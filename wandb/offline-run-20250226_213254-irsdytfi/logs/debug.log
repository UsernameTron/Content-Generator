2025-02-26 21:32:54,084 INFO    MainThread:9441 [wandb_setup.py:_flush():76] Current SDK version is 0.16.6
2025-02-26 21:32:54,084 INFO    MainThread:9441 [wandb_setup.py:_flush():76] Configure stats pid to 9441
2025-02-26 21:32:54,084 INFO    MainThread:9441 [wandb_setup.py:_flush():76] Loading settings from /Users/cpconnor/.config/wandb/settings
2025-02-26 21:32:54,084 INFO    MainThread:9441 [wandb_setup.py:_flush():76] Loading settings from /Users/cpconnor/CascadeProjects/multi-platform-content-generator/wandb/settings
2025-02-26 21:32:54,084 INFO    MainThread:9441 [wandb_setup.py:_flush():76] Loading settings from environment variables: {'mode': 'offline'}
2025-02-26 21:32:54,084 INFO    MainThread:9441 [wandb_setup.py:_flush():76] Applying setup settings: {'_disable_service': False}
2025-02-26 21:32:54,084 INFO    MainThread:9441 [wandb_setup.py:_flush():76] Inferring run settings from compute environment: {'program_relpath': 'finetune_model.py', 'program_abspath': '/Users/cpconnor/CascadeProjects/multi-platform-content-generator/finetune_model.py', 'program': '/Users/cpconnor/CascadeProjects/multi-platform-content-generator/finetune_model.py'}
2025-02-26 21:32:54,084 INFO    MainThread:9441 [wandb_init.py:_log_setup():521] Logging user logs to /Users/cpconnor/CascadeProjects/multi-platform-content-generator/wandb/offline-run-20250226_213254-irsdytfi/logs/debug.log
2025-02-26 21:32:54,084 INFO    MainThread:9441 [wandb_init.py:_log_setup():522] Logging internal logs to /Users/cpconnor/CascadeProjects/multi-platform-content-generator/wandb/offline-run-20250226_213254-irsdytfi/logs/debug-internal.log
2025-02-26 21:32:54,084 INFO    MainThread:9441 [wandb_init.py:init():561] calling init triggers
2025-02-26 21:32:54,084 INFO    MainThread:9441 [wandb_init.py:init():568] wandb.init called with sweep_config: {}
config: {'base_model': 'EleutherAI/pythia-1.4b', 'training_config': {'lora_r': 16, 'lora_alpha': 16, 'lora_dropout': 0.05, 'target_modules': ['query_key_value', 'dense', 'dense_h_to_4h', 'dense_4h_to_h'], 'bias': 'none', 'task_type': 'CAUSAL_LM', 'training_args': {'per_device_train_batch_size': 4, 'gradient_accumulation_steps': 4, 'warmup_steps': 100, 'max_steps': 1000, 'learning_rate': 0.0003, 'fp16': True, 'logging_steps': 10, 'output_dir': './outputs/finetune', 'save_strategy': 'steps', 'save_steps': 200, 'evaluation_strategy': 'steps', 'eval_steps': 200, 'report_to': 'wandb'}}, 'data_config': {'train_file': 'data/training/pete_connor_style.jsonl', 'validation_file': 'data/training/pete_connor_validation.jsonl', 'preprocessing_num_workers': 4, 'max_seq_length': 512, 'overwrite_cache': False, 'pad_to_max_length': True}, 'wandb_config': {'project': 'pete-connor-cx-ai-expert', 'name': 'cx-ai-ml-expertise-run', 'tags': ['cx-ai-expert', 'customer-experience', 'machine-learning', 'satirical-tech-expert', 'lora-finetuning'], 'notes': "Fine-tuning run for C. Pete Connor's expertise in customer experience, AI, and machine learning"}, 'custom_loss_config': {'penalized_phrases': ['game changer', "here's the kicker", 'cutting-edge', 'revolutionary', 'disruptive', 'innovative', 'next-generation', 'state-of-the-art', 'seamless customer journey', 'delightful experience', 'customer-centric', 'AI-powered experience', 'frictionless', 'hyper-personalization', 'digital transformation', 'customer obsession'], 'rewarded_phrases': ['paradoxically', 'absurdly', 'statistically speaking', 'data shows', 'ironically', 'contrary to popular belief', 'in stark contrast to the marketing', 'customer experience data indicates', 'model bias reveals', 'sentiment analysis demonstrates', 'customer retention metrics show', 'NPS fails to capture', 'ML models often amplify', 'AI implementation reality', 'CX automation paradox'], 'penalty_weight': 0.5, 'reward_weight': 0.5}}
2025-02-26 21:32:54,084 INFO    MainThread:9441 [wandb_init.py:init():611] starting backend
2025-02-26 21:32:54,084 INFO    MainThread:9441 [wandb_init.py:init():615] setting up manager
2025-02-26 21:32:54,085 INFO    MainThread:9441 [backend.py:_multiprocessing_setup():105] multiprocessing start_methods=spawn,fork,forkserver, using: spawn
2025-02-26 21:32:54,085 INFO    MainThread:9441 [wandb_init.py:init():623] backend started and connected
2025-02-26 21:32:54,088 INFO    MainThread:9441 [wandb_init.py:init():715] updated telemetry
2025-02-26 21:32:54,089 INFO    MainThread:9441 [wandb_init.py:init():748] communicating run to backend with 90.0 second timeout
2025-02-26 21:32:54,090 INFO    MainThread:9441 [wandb_init.py:init():799] starting run threads in backend
2025-02-26 21:32:54,141 INFO    MainThread:9441 [wandb_run.py:_console_start():2335] atexit reg
2025-02-26 21:32:54,141 INFO    MainThread:9441 [wandb_run.py:_redirect():2190] redirect: wrap_raw
2025-02-26 21:32:54,141 INFO    MainThread:9441 [wandb_run.py:_redirect():2255] Wrapping output streams.
2025-02-26 21:32:54,141 INFO    MainThread:9441 [wandb_run.py:_redirect():2280] Redirects installed.
2025-02-26 21:32:54,141 INFO    MainThread:9441 [wandb_init.py:init():842] run started, returning control to user process
2025-02-26 21:32:55,910 INFO    MainThread:9441 [wandb_run.py:_config_callback():1347] config_cb None None {'peft_config': {'default': {'task_type': <TaskType.CAUSAL_LM: 'CAUSAL_LM'>, 'peft_type': <PeftType.LORA: 'LORA'>, 'auto_mapping': None, 'base_model_name_or_path': 'EleutherAI/pythia-1.4b', 'revision': None, 'inference_mode': False, 'r': 16, 'target_modules': {'dense_h_to_4h', 'dense', 'query_key_value', 'dense_4h_to_h'}, 'exclude_modules': None, 'lora_alpha': 16, 'lora_dropout': 0.05, 'fan_in_fan_out': False, 'bias': 'none', 'use_rslora': False, 'modules_to_save': None, 'init_lora_weights': True, 'layers_to_transform': None, 'layers_pattern': None, 'rank_pattern': {}, 'alpha_pattern': {}, 'megatron_config': None, 'megatron_core': 'megatron.core', 'loftq_config': {}, 'eva_config': None, 'use_dora': False, 'layer_replication': None, 'runtime_config': {'ephemeral_gpu_offload': False}, 'lora_bias': False}}, 'return_dict': True, 'output_hidden_states': False, 'output_attentions': False, 'torchscript': False, 'torch_dtype': 'float32', 'use_bfloat16': False, 'tf_legacy_loss': False, 'pruned_heads': {}, 'tie_word_embeddings': False, 'chunk_size_feed_forward': 0, 'is_encoder_decoder': False, 'is_decoder': False, 'cross_attention_hidden_size': None, 'add_cross_attention': False, 'tie_encoder_decoder': False, 'max_length': 20, 'min_length': 0, 'do_sample': False, 'early_stopping': False, 'num_beams': 1, 'num_beam_groups': 1, 'diversity_penalty': 0.0, 'temperature': 1.0, 'top_k': 50, 'top_p': 1.0, 'typical_p': 1.0, 'repetition_penalty': 1.0, 'length_penalty': 1.0, 'no_repeat_ngram_size': 0, 'encoder_no_repeat_ngram_size': 0, 'bad_words_ids': None, 'num_return_sequences': 1, 'output_scores': False, 'return_dict_in_generate': False, 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'remove_invalid_values': False, 'exponential_decay_length_penalty': None, 'suppress_tokens': None, 'begin_suppress_tokens': None, 'architectures': ['GPTNeoXForCausalLM'], 'finetuning_task': None, 'id2label': {0: 'LABEL_0', 1: 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'tokenizer_class': None, 'prefix': None, 'bos_token_id': 0, 'pad_token_id': None, 'eos_token_id': 0, 'sep_token_id': None, 'decoder_start_token_id': None, 'task_specific_params': None, 'problem_type': None, '_name_or_path': 'EleutherAI/pythia-1.4b', '_attn_implementation_autoset': True, 'transformers_version': '4.49.0', 'model_type': 'gpt_neox', 'vocab_size': 50304, 'max_position_embeddings': 2048, 'hidden_size': 2048, 'num_hidden_layers': 24, 'num_attention_heads': 16, 'intermediate_size': 8192, 'hidden_act': 'gelu', 'rotary_pct': 0.25, 'partial_rotary_factor': 0.25, 'rotary_emb_base': 10000, 'rope_theta': 10000, 'attention_dropout': 0.0, 'hidden_dropout': 0.0, 'classifier_dropout': 0.1, 'initializer_range': 0.02, 'layer_norm_eps': 1e-05, 'use_cache': True, 'use_parallel_residual': True, 'rope_scaling': None, 'attention_bias': True, 'output_dir': './outputs/finetune', 'overwrite_output_dir': False, 'do_train': False, 'do_eval': True, 'do_predict': False, 'eval_strategy': 'steps', 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 8, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 4, 'eval_accumulation_steps': None, 'eval_delay': 0, 'torch_empty_cache_steps': None, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 1000, 'lr_scheduler_type': 'linear', 'lr_scheduler_kwargs': {}, 'warmup_ratio': 0.0, 'warmup_steps': 100, 'log_level': 'passive', 'log_level_replica': 'warning', 'log_on_each_node': True, 'logging_dir': './outputs/finetune/runs/Feb26_21-32-55_Mac.lan', 'logging_strategy': 'steps', 'logging_first_step': False, 'logging_steps': 10, 'logging_nan_inf_filter': True, 'save_strategy': 'steps', 'save_steps': 200, 'save_total_limit': None, 'save_safetensors': True, 'save_on_each_node': False, 'save_only_model': False, 'restore_callback_states_from_checkpoint': False, 'no_cuda': False, 'use_cpu': False, 'use_mps_device': False, 'seed': 42, 'data_seed': None, 'jit_mode_eval': False, 'use_ipex': False, 'bf16': False, 'fp16': False, 'fp16_opt_level': 'O1', 'half_precision_backend': 'auto', 'bf16_full_eval': False, 'fp16_full_eval': False, 'tf32': None, 'local_rank': 0, 'ddp_backend': None, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': [], 'dataloader_drop_last': False, 'eval_steps': 200, 'dataloader_num_workers': 0, 'dataloader_prefetch_factor': None, 'past_index': -1, 'run_name': './outputs/finetune', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'ignore_data_skip': False, 'fsdp': [], 'fsdp_min_num_params': 0, 'fsdp_config': {'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False}, 'fsdp_transformer_layer_cls_to_wrap': None, 'accelerator_config': {'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None}, 'deepspeed': None, 'label_smoothing_factor': 0.0, 'optim': 'adamw_torch', 'optim_args': None, 'adafactor': False, 'group_by_length': False, 'length_column_name': 'length', 'report_to': ['wandb'], 'ddp_find_unused_parameters': None, 'ddp_bucket_cap_mb': None, 'ddp_broadcast_buffers': None, 'dataloader_pin_memory': True, 'dataloader_persistent_workers': False, 'skip_memory_metrics': True, 'use_legacy_prediction_loop': False, 'push_to_hub': False, 'resume_from_checkpoint': None, 'hub_model_id': None, 'hub_strategy': 'every_save', 'hub_token': '<HUB_TOKEN>', 'hub_private_repo': None, 'hub_always_push': False, 'gradient_checkpointing': False, 'gradient_checkpointing_kwargs': None, 'include_inputs_for_metrics': False, 'include_for_metrics': [], 'eval_do_concat_batches': True, 'fp16_backend': 'auto', 'evaluation_strategy': 'steps', 'push_to_hub_model_id': None, 'push_to_hub_organization': None, 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'mp_parameters': '', 'auto_find_batch_size': False, 'full_determinism': False, 'torchdynamo': None, 'ray_scope': 'last', 'ddp_timeout': 1800, 'torch_compile': False, 'torch_compile_backend': None, 'torch_compile_mode': None, 'dispatch_batches': None, 'split_batches': None, 'include_tokens_per_second': False, 'include_num_input_tokens_seen': False, 'neftune_noise_alpha': None, 'optim_target_modules': None, 'batch_eval_metrics': False, 'eval_on_start': False, 'use_liger_kernel': False, 'eval_use_gather_object': False, 'average_tokens_across_devices': False}
2025-02-26 21:32:55,912 INFO    MainThread:9441 [wandb_config.py:__setitem__():151] config set model/num_parameters = 1427230720 - <bound method Run._config_callback of <wandb.sdk.wandb_run.Run object at 0x138cfd7f0>>
2025-02-26 21:32:55,912 INFO    MainThread:9441 [wandb_run.py:_config_callback():1347] config_cb model/num_parameters 1427230720 None
2025-02-26 21:32:56,524 INFO    MainThread:9441 [wandb_run.py:_finish():2064] finishing run pete-connor-cx-ai-expert/irsdytfi
2025-02-26 21:32:56,524 INFO    MainThread:9441 [wandb_run.py:_atexit_cleanup():2304] got exitcode: 0
2025-02-26 21:32:56,524 INFO    MainThread:9441 [wandb_run.py:_restore():2287] restore
2025-02-26 21:32:56,524 INFO    MainThread:9441 [wandb_run.py:_restore():2293] restore done
2025-02-26 21:32:57,532 INFO    MainThread:9441 [wandb_run.py:_footer_history_summary_info():3936] rendering history
2025-02-26 21:32:57,532 INFO    MainThread:9441 [wandb_run.py:_footer_history_summary_info():3968] rendering summary
