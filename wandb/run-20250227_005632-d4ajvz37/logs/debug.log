2025-02-27 00:56:32,128 INFO    MainThread:16935 [wandb_setup.py:_flush():76] Current SDK version is 0.16.6
2025-02-27 00:56:32,128 INFO    MainThread:16935 [wandb_setup.py:_flush():76] Configure stats pid to 16935
2025-02-27 00:56:32,128 INFO    MainThread:16935 [wandb_setup.py:_flush():76] Loading settings from /Users/cpconnor/.config/wandb/settings
2025-02-27 00:56:32,128 INFO    MainThread:16935 [wandb_setup.py:_flush():76] Loading settings from /Users/cpconnor/CascadeProjects/multi-platform-content-generator/wandb/settings
2025-02-27 00:56:32,128 INFO    MainThread:16935 [wandb_setup.py:_flush():76] Loading settings from environment variables: {}
2025-02-27 00:56:32,128 INFO    MainThread:16935 [wandb_setup.py:_flush():76] Applying setup settings: {'_disable_service': False}
2025-02-27 00:56:32,128 INFO    MainThread:16935 [wandb_setup.py:_flush():76] Inferring run settings from compute environment: {'program_relpath': 'run_overnight_training.py', 'program_abspath': '/Users/cpconnor/CascadeProjects/multi-platform-content-generator/run_overnight_training.py', 'program': '/Users/cpconnor/CascadeProjects/multi-platform-content-generator/run_overnight_training.py'}
2025-02-27 00:56:32,128 INFO    MainThread:16935 [wandb_setup.py:_flush():76] Applying login settings: {}
2025-02-27 00:56:32,128 INFO    MainThread:16935 [wandb_init.py:_log_setup():521] Logging user logs to /Users/cpconnor/CascadeProjects/multi-platform-content-generator/wandb/run-20250227_005632-d4ajvz37/logs/debug.log
2025-02-27 00:56:32,128 INFO    MainThread:16935 [wandb_init.py:_log_setup():522] Logging internal logs to /Users/cpconnor/CascadeProjects/multi-platform-content-generator/wandb/run-20250227_005632-d4ajvz37/logs/debug-internal.log
2025-02-27 00:56:32,128 INFO    MainThread:16935 [wandb_init.py:init():561] calling init triggers
2025-02-27 00:56:32,129 INFO    MainThread:16935 [wandb_init.py:init():568] wandb.init called with sweep_config: {}
config: {'base_model': 'EleutherAI/pythia-1.4b', 'training_config': {'lora_r': 8, 'lora_alpha': 16, 'lora_dropout': 0.05, 'target_modules': ['query_key_value', 'dense', 'dense_h_to_4h', 'dense_4h_to_h'], 'bias': 'none', 'task_type': 'CAUSAL_LM', 'training_args': {'output_dir': './outputs/finetune', 'evaluation_strategy': 'steps', 'eval_steps': 100, 'logging_steps': 10, 'save_steps': 7200, 'save_total_limit': 5, 'learning_rate': 2e-05, 'weight_decay': 0.01, 'fp16': True, 'bf16': False, 'max_grad_norm': 0.3, 'max_steps': -1, 'num_train_epochs': 10, 'warmup_ratio': 0.03, 'group_by_length': True, 'lr_scheduler_type': 'cosine', 'report_to': 'wandb', 'gradient_checkpointing': True, 'gradient_accumulation_steps': 8, 'per_device_train_batch_size': 1, 'per_device_eval_batch_size': 1, 'run_name': 'overnight-full-training-run'}}, 'data_config': {'train_file': 'data/training_data.jsonl', 'validation_file': 'data/validation_data.jsonl', 'preprocessing_num_workers': 4, 'max_seq_length': 1024, 'overwrite_cache': False, 'pad_to_max_length': True}, 'wandb_config': {'project': 'pete-connor-cx-ai-expert', 'name': 'overnight-full-training-run', 'tags': ['cx-ai-expert', 'customer-experience', 'machine-learning', 'satirical-tech-expert', 'lora-finetuning', 'continuous-training'], 'notes': "Overnight continuous training run for C. Pete Connor's expertise in customer experience, AI, and ML with enhanced anti-pattern training"}, 'custom_loss_config': {'penalized_phrases': ['game changer', "here's the kicker", 'cutting-edge', 'revolutionary', 'disruptive', 'innovative', 'next-generation', 'state-of-the-art', 'seamless customer journey', 'delightful experience', 'customer-centric', 'AI-powered experience', 'frictionless', 'hyper-personalization', 'digital transformation', 'customer obsession', 'paradigm shift', 'market disruption', 'synergy', 'leverage', 'holistic approach', 'seamless integration', 'robust solution', 'scalable architecture', 'best-in-class', 'end-to-end solution', 'turnkey solution', 'low-hanging fruit', 'think outside the box', 'moving the needle', 'overuse of em dash', 'overuse of en dash', 'artificial transitions', 'symmetric sentence structures'], 'rewarded_phrases': ['paradoxically', 'absurdly', 'statistically speaking', 'data shows', 'ironically', 'contrary to popular belief', 'in stark contrast to the marketing', 'customer experience data indicates', 'model bias reveals', 'sentiment analysis demonstrates', 'customer retention metrics show', 'NPS fails to capture', 'ML models often amplify', 'AI implementation reality', 'CX automation paradox', 'sarcastically speaking', 'technical reality diverges', 'vendor claims notwithstanding', 'benchmarks contradict', 'despite executive optimism', 'practical implementation shows', 'user testing reveals', 'cynical interpretation suggests', 'empirical evidence contradicts', 'when examined closely'], 'penalty_weight': 0.7, 'reward_weight': 0.6}, 'continuous_training': True, 'checkpoint_interval_seconds': 7200}
2025-02-27 00:56:32,129 INFO    MainThread:16935 [wandb_init.py:init():611] starting backend
2025-02-27 00:56:32,129 INFO    MainThread:16935 [wandb_init.py:init():615] setting up manager
2025-02-27 00:56:32,129 INFO    MainThread:16935 [backend.py:_multiprocessing_setup():105] multiprocessing start_methods=spawn,fork,forkserver, using: spawn
2025-02-27 00:56:32,131 INFO    MainThread:16935 [wandb_init.py:init():623] backend started and connected
2025-02-27 00:56:32,132 INFO    MainThread:16935 [wandb_init.py:init():715] updated telemetry
2025-02-27 00:56:32,132 INFO    MainThread:16935 [wandb_init.py:init():748] communicating run to backend with 90.0 second timeout
2025-02-27 00:56:32,421 INFO    MainThread:16935 [wandb_run.py:_on_init():2357] communicating current version
2025-02-27 00:56:32,560 INFO    MainThread:16935 [wandb_run.py:_on_init():2366] got version response upgrade_message: "wandb version 0.19.7 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"

2025-02-27 00:56:32,560 INFO    MainThread:16935 [wandb_init.py:init():799] starting run threads in backend
2025-02-27 00:56:32,639 INFO    MainThread:16935 [wandb_run.py:_console_start():2335] atexit reg
2025-02-27 00:56:32,639 INFO    MainThread:16935 [wandb_run.py:_redirect():2190] redirect: wrap_raw
2025-02-27 00:56:32,640 INFO    MainThread:16935 [wandb_run.py:_redirect():2255] Wrapping output streams.
2025-02-27 00:56:32,640 INFO    MainThread:16935 [wandb_run.py:_redirect():2280] Redirects installed.
2025-02-27 00:56:32,640 INFO    MainThread:16935 [wandb_init.py:init():842] run started, returning control to user process
2025-02-27 00:56:45,694 INFO    MainThread:16935 [wandb_run.py:_finish():2064] finishing run cpeteconnor-fiverr/pete-connor-cx-ai-expert/d4ajvz37
2025-02-27 00:56:45,694 INFO    MainThread:16935 [wandb_run.py:_atexit_cleanup():2304] got exitcode: 0
2025-02-27 00:56:45,694 INFO    MainThread:16935 [wandb_run.py:_restore():2287] restore
2025-02-27 00:56:45,694 INFO    MainThread:16935 [wandb_run.py:_restore():2293] restore done
2025-02-27 00:56:49,260 INFO    MainThread:16935 [wandb_run.py:_footer_history_summary_info():3936] rendering history
2025-02-27 00:56:49,261 INFO    MainThread:16935 [wandb_run.py:_footer_history_summary_info():3968] rendering summary
2025-02-27 00:56:49,267 INFO    MainThread:16935 [wandb_run.py:_footer_sync_info():3895] logging synced files
