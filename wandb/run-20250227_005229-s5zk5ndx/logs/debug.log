2025-02-27 00:52:29,425 INFO    MainThread:16461 [wandb_setup.py:_flush():76] Current SDK version is 0.16.6
2025-02-27 00:52:29,425 INFO    MainThread:16461 [wandb_setup.py:_flush():76] Configure stats pid to 16461
2025-02-27 00:52:29,425 INFO    MainThread:16461 [wandb_setup.py:_flush():76] Loading settings from /Users/cpconnor/.config/wandb/settings
2025-02-27 00:52:29,425 INFO    MainThread:16461 [wandb_setup.py:_flush():76] Loading settings from /Users/cpconnor/CascadeProjects/multi-platform-content-generator/wandb/settings
2025-02-27 00:52:29,425 INFO    MainThread:16461 [wandb_setup.py:_flush():76] Loading settings from environment variables: {}
2025-02-27 00:52:29,425 INFO    MainThread:16461 [wandb_setup.py:_flush():76] Applying setup settings: {'_disable_service': False}
2025-02-27 00:52:29,425 INFO    MainThread:16461 [wandb_setup.py:_flush():76] Inferring run settings from compute environment: {'program_relpath': 'run_overnight_training.py', 'program_abspath': '/Users/cpconnor/CascadeProjects/multi-platform-content-generator/run_overnight_training.py', 'program': '/Users/cpconnor/CascadeProjects/multi-platform-content-generator/run_overnight_training.py'}
2025-02-27 00:52:29,425 INFO    MainThread:16461 [wandb_setup.py:_flush():76] Applying login settings: {}
2025-02-27 00:52:29,425 INFO    MainThread:16461 [wandb_init.py:_log_setup():521] Logging user logs to /Users/cpconnor/CascadeProjects/multi-platform-content-generator/wandb/run-20250227_005229-s5zk5ndx/logs/debug.log
2025-02-27 00:52:29,426 INFO    MainThread:16461 [wandb_init.py:_log_setup():522] Logging internal logs to /Users/cpconnor/CascadeProjects/multi-platform-content-generator/wandb/run-20250227_005229-s5zk5ndx/logs/debug-internal.log
2025-02-27 00:52:29,426 INFO    MainThread:16461 [wandb_init.py:init():561] calling init triggers
2025-02-27 00:52:29,426 INFO    MainThread:16461 [wandb_init.py:init():568] wandb.init called with sweep_config: {}
config: {'base_model': 'EleutherAI/pythia-1.4b', 'training_config': {'lora_r': 8, 'lora_alpha': 16, 'lora_dropout': 0.05, 'target_modules': ['query_key_value', 'dense', 'dense_h_to_4h', 'dense_4h_to_h'], 'bias': 'none', 'task_type': 'CAUSAL_LM', 'training_args': {'output_dir': './outputs/finetune', 'evaluation_strategy': 'steps', 'eval_steps': 100, 'logging_steps': 10, 'save_steps': 7200, 'save_total_limit': 5, 'learning_rate': 2e-05, 'weight_decay': 0.01, 'fp16': True, 'bf16': False, 'max_grad_norm': 0.3, 'max_steps': -1, 'num_train_epochs': 10, 'warmup_ratio': 0.03, 'group_by_length': True, 'lr_scheduler_type': 'cosine', 'report_to': 'wandb', 'gradient_checkpointing': True, 'gradient_accumulation_steps': 4, 'per_device_train_batch_size': 8, 'per_device_eval_batch_size': 8, 'run_name': 'overnight-full-training-run'}}, 'data_config': {'train_file': 'data/training_data.jsonl', 'validation_file': 'data/training_data.jsonl', 'preprocessing_num_workers': 4, 'max_seq_length': 2048, 'overwrite_cache': False, 'pad_to_max_length': True}, 'wandb_config': {'project': 'pete-connor-cx-ai-expert', 'name': 'overnight-full-training-run', 'tags': ['cx-ai-expert', 'customer-experience', 'machine-learning', 'satirical-tech-expert', 'lora-finetuning', 'continuous-training'], 'notes': "Overnight continuous training run for C. Pete Connor's expertise in customer experience, AI, and ML with enhanced anti-pattern training"}, 'custom_loss_config': {'penalized_phrases': ['game changer', "here's the kicker", 'cutting-edge', 'revolutionary', 'disruptive', 'innovative', 'next-generation', 'state-of-the-art', 'seamless customer journey', 'delightful experience', 'customer-centric', 'AI-powered experience', 'frictionless', 'hyper-personalization', 'digital transformation', 'customer obsession', 'paradigm shift', 'market disruption', 'synergy', 'leverage', 'holistic approach', 'seamless integration', 'robust solution', 'scalable architecture', 'best-in-class', 'end-to-end solution', 'turnkey solution', 'low-hanging fruit', 'think outside the box', 'moving the needle', 'overuse of em dash', 'overuse of en dash', 'artificial transitions', 'symmetric sentence structures'], 'rewarded_phrases': ['paradoxically', 'absurdly', 'statistically speaking', 'data shows', 'ironically', 'contrary to popular belief', 'in stark contrast to the marketing', 'customer experience data indicates', 'model bias reveals', 'sentiment analysis demonstrates', 'customer retention metrics show', 'NPS fails to capture', 'ML models often amplify', 'AI implementation reality', 'CX automation paradox', 'sarcastically speaking', 'technical reality diverges', 'vendor claims notwithstanding', 'benchmarks contradict', 'despite executive optimism', 'practical implementation shows', 'user testing reveals', 'cynical interpretation suggests', 'empirical evidence contradicts', 'when examined closely'], 'penalty_weight': 0.7, 'reward_weight': 0.6}, 'continuous_training': True, 'checkpoint_interval_seconds': 7200}
2025-02-27 00:52:29,426 INFO    MainThread:16461 [wandb_init.py:init():611] starting backend
2025-02-27 00:52:29,426 INFO    MainThread:16461 [wandb_init.py:init():615] setting up manager
2025-02-27 00:52:29,427 INFO    MainThread:16461 [backend.py:_multiprocessing_setup():105] multiprocessing start_methods=spawn,fork,forkserver, using: spawn
2025-02-27 00:52:29,428 INFO    MainThread:16461 [wandb_init.py:init():623] backend started and connected
2025-02-27 00:52:29,430 INFO    MainThread:16461 [wandb_init.py:init():715] updated telemetry
2025-02-27 00:52:29,430 INFO    MainThread:16461 [wandb_init.py:init():748] communicating run to backend with 90.0 second timeout
2025-02-27 00:52:29,742 INFO    MainThread:16461 [wandb_run.py:_on_init():2357] communicating current version
2025-02-27 00:52:29,868 INFO    MainThread:16461 [wandb_run.py:_on_init():2366] got version response upgrade_message: "wandb version 0.19.7 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"

2025-02-27 00:52:29,868 INFO    MainThread:16461 [wandb_init.py:init():799] starting run threads in backend
2025-02-27 00:52:29,934 INFO    MainThread:16461 [wandb_run.py:_console_start():2335] atexit reg
2025-02-27 00:52:29,934 INFO    MainThread:16461 [wandb_run.py:_redirect():2190] redirect: wrap_raw
2025-02-27 00:52:29,934 INFO    MainThread:16461 [wandb_run.py:_redirect():2255] Wrapping output streams.
2025-02-27 00:52:29,934 INFO    MainThread:16461 [wandb_run.py:_redirect():2280] Redirects installed.
2025-02-27 00:52:29,935 INFO    MainThread:16461 [wandb_init.py:init():842] run started, returning control to user process
2025-02-27 00:52:29,945 INFO    MainThread:16461 [wandb_run.py:_finish():2064] finishing run cpeteconnor-fiverr/pete-connor-cx-ai-expert/s5zk5ndx
2025-02-27 00:52:29,945 INFO    MainThread:16461 [wandb_run.py:_atexit_cleanup():2304] got exitcode: 0
2025-02-27 00:52:29,945 INFO    MainThread:16461 [wandb_run.py:_restore():2287] restore
2025-02-27 00:52:29,945 INFO    MainThread:16461 [wandb_run.py:_restore():2293] restore done
2025-02-27 00:52:33,463 INFO    MainThread:16461 [wandb_run.py:_footer_history_summary_info():3936] rendering history
2025-02-27 00:52:33,463 INFO    MainThread:16461 [wandb_run.py:_footer_history_summary_info():3968] rendering summary
2025-02-27 00:52:33,465 INFO    MainThread:16461 [wandb_run.py:_footer_sync_info():3895] logging synced files
